{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mecxlan/ML_GPT-3.5_img_classification/blob/main/ChatGPT_ML_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guided Project\n",
        "\n",
        "## **Machine Learning with ChatGPT: Image Classification Model**\n",
        "\n",
        "Author: [mecxlan](https://www.linkedin.com/in/mecxlan/)\n",
        "\n",
        "## Source for Guidance\n",
        "\n",
        "[Slides - ChatGPT - Jousef Murad.pdf - Google Drive](https://drive.google.com/file/d/1XyrgMSjHxG8LjQ7wENDn0-_-NxOzSptI/view)\n",
        "\n",
        "[ChatGPT_ML_Coursera.ipynb](https://colab.research.google.com/drive/1pDGUqdqxvN7uubtIIg9bVcHqQhUme43i?usp=sharing)\n",
        "\n",
        "[Intro to Machine learning with py](https://pdfroom.com/books/introduction-to-machine-learning-with-python-a-guide-for-data-scientists/qjb5q6ykdxQ/)\n",
        "\n",
        "[ChatGPT](https://chat.openai.com/auth/login?next=%2F)"
      ],
      "metadata": {
        "id": "AuzxV3DR-MLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Built a Neural Network with MNIST Using Keras\n",
        "\n",
        "\n",
        "```\n",
        "# Prompt:\n",
        "\"Write Python code of neural network to solve the MNIST\n",
        " problem using Keras using fully connected layers and\n",
        "  categorical crossentropy as the loss function without\n",
        "  evaluating the model on the test set\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "EVFlrkWIBmAQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcde8c36-EIg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Load MNIST dataset and preprocess it\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 784).astype('float32') / 255\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1, verbose=2)\n",
        "\n",
        "# The model has been trained on the training set but not evaluated on the test set as requested"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune Code to Change Loss Fucntion\n",
        "  Substitute Loss Function\n"
      ],
      "metadata": {
        "id": "8DhFU7VLXw4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Prompt:\n",
        "  \"Change the loss function to be sparse categorial crossentropy\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "w-b7OUUeZEbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Load MNIST dataset and preprocess it\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 784).astype('float32') / 255\n",
        "\n",
        "# Use sparse categorical crossentropy for the loss function\n",
        "# Note: No need to one-hot encode the target labels (y_train and y_test)\n",
        "y_train = y_train.astype('int32')\n",
        "y_test = y_test.astype('int32')\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model with sparse categorical crossentropy as the loss function\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1, verbose=2)\n",
        "\n",
        "# The model has been trained using sparse categorical crossentropy as the loss function."
      ],
      "metadata": {
        "id": "v-Tjk-24SGs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Update to Use Convolutional Layers\n",
        "  Substitute Fully Connected Layer with Convolutional Layers"
      ],
      "metadata": {
        "id": "Cx1_FqwWaaWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Prompt:\n",
        "  \"Use convolutional Layers\"\n",
        "\n",
        "# Prompt:\n",
        "  \"TypeError: cannot unpack non-iterable float object -fix that\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "j3lC_EMta1ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST dataset and preprocess it\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define the convolutional neural network model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model with categorical crossentropy as the loss function\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1, verbose=2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss_and_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Test loss: {loss_and_accuracy[0]:.4f}, Test accuracy: {loss_and_accuracy[1]:.4f}')"
      ],
      "metadata": {
        "id": "BZ6M06wVaD1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Model & Create Validation Set\n",
        "  Evaluate model performance & accuracy and create validation set to keep track of overfitting"
      ],
      "metadata": {
        "id": "Pitu8zm4f2M7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Prompt:\n",
        "  \"Evaluate the model using its test set\"\n",
        "  \"Use 20% of the training set as a validation set\"\n",
        "```\n",
        "[Displaying image data in TensorBoard](https://www.tensorflow.org/tensorboard/image_summaries)\n"
      ],
      "metadata": {
        "id": "K1yGsP1mgI9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST dataset and preprocess it\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Use 20% of the training set as the validation set\n",
        "validation_split = 0.2\n",
        "split_index = int(x_train.shape[0] * (1 - validation_split))\n",
        "x_train, x_val = x_train[:split_index], x_train[split_index:]\n",
        "y_train, y_val = y_train[:split_index], y_train[split_index:]\n",
        "\n",
        "# Define the convolutional neural network model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model with categorical crossentropy as the loss function and accuracy as a metric\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with validation set\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val), verbose=2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "7mO_cI9VezCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Training & Validation Losss & Random Images\n",
        "  Plot Losses using Matplotlib and random image to check accuracy visually"
      ],
      "metadata": {
        "id": "jqrwjFRpxS6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Prompt: \"plot the training and test loss using using matplotlib\"\n",
        "\n",
        "# Prompt: \"plot 20 random images with label from the training set and\n",
        " see if the model predicts the images correct by color coding\n",
        "  wrong predictions with red and right predictions with green\"\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GLN2GG75xiTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Load MNIST dataset and preprocess it\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Use 20% of the training set as the validation set\n",
        "validation_split = 0.2\n",
        "split_index = int(x_train.shape[0] * (1 - validation_split))\n",
        "x_train, x_val = x_train[:split_index], x_train[split_index:]\n",
        "y_train, y_val = y_train[:split_index], y_train[split_index:]\n",
        "\n",
        "# Define the convolutional neural network model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model with categorical crossentropy as the loss function and accuracy as a metric\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with validation set and record history\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val), verbose=2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Plot the training and validation loss\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(1, epochs+1)\n",
        "\n",
        "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Visualize 20 random images with color-coded predictions\n",
        "num_images = 20\n",
        "random_indices = random.sample(range(x_train.shape[0]), num_images)\n",
        "predictions = model.predict(x_train[random_indices])\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(num_images):\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    plt.imshow(x_train[random_indices[i]].reshape(28, 28), cmap='gray')\n",
        "    if predicted_classes[i] == np.argmax(y_train[random_indices[i]]):\n",
        "        plt.title(f\"True: {np.argmax(y_train[random_indices[i]])}\\nPredicted: {predicted_classes[i]}\", color='green')\n",
        "    else:\n",
        "        plt.title(f\"True: {np.argmax(y_train[random_indices[i]])}\\nPredicted: {predicted_classes[i]}\", color='red')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tFP_e6uSqDYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "Make sure to use the prompt\n",
        " \"select the best hyperparameters\n",
        "  for this problem\" and ChatGPT will\n",
        "   come up with a list of suggested\n",
        "    hyperparameters that you can tune & even\n",
        "     suggests code that you can copy and paste.\n",
        "\n",
        "                  _Jousef Murad\n",
        "\n",
        "  Prompt: \"You are a ChatGPT model.\n",
        "  Please provide me with the Python code for\n",
        "   a neural network using Keras to solve the MNIST problem\n",
        "    with convolutional layers, categorical crossentropy loss,\n",
        "     and Adam optimizer. Also, plot the training and test loss\n",
        "      using matplotlib and visualize 20 random images with\n",
        "      color-coded predictions from the training set.\n",
        "\"\n",
        "```"
      ],
      "metadata": {
        "id": "uz-m3dtW2cNd"
      }
    }
  ]
}